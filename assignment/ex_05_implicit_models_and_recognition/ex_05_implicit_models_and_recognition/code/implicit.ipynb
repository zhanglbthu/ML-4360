{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLNmHbhXipET"
      },
      "source": [
        "# Computer Vision Lecture - Exercise 5 Part 1 - Implicit Models\n",
        "\n",
        "In this exercise, you will gain hands-on experience regarding 3D representations of objects. More specifically, we will train our own simple Occupancy Network to represent a 3D shape implicitly and learn how to extract a mesh from such an implicit representation!\n",
        "\n",
        "This notebook guides you through the relevant steps. When you see helper functions, you don't need to do anything - they are already implemented. The functions you need to implement are indicated as Exercise Function. Sometimes, you can find Hints - these are written upside-down so you can first try to find the solution without reading them.\n",
        "\n",
        "Good luck and lot's of fun!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTbm8SCQl9L_"
      },
      "source": [
        "## Preliminaries\n",
        "Let's first install dependencies, import libaries and define the input and output directories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l303j6MMNMgP"
      },
      "outputs": [],
      "source": [
        "!pip install livelossplot --quiet\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from livelossplot import PlotLosses\n",
        "from skimage.measure import marching_cubes_lewiner as marching_cubes    # Lewiner et al. algorithm is faster, resolves ambiguities, and guarantees topologically correct results\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# set random seed for reproducability\n",
        "np.random.seed(42)\n",
        "\n",
        "data_dir = 'data'\n",
        "out_dir = 'output'\n",
        "\n",
        "for d in [data_dir, out_dir]:\n",
        "  os.makedirs(d, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiZoIiNXngRf"
      },
      "source": [
        "Next, we need to import our training data, i.e. the 3D object that we want to represent. If you use Google Colab, drag the file `code/data/points.npz` from the exercise folder in `data`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvd6LkXzq21w"
      },
      "source": [
        "The file contains 100k sampling points together with their occupancy value. The occupancy value indicates if the point belongs to the object (`occupancy=1`) or to free space (`occupancy=0`). \\\\\n",
        "We now define some helper functions to load and visualize the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6JhqC2YqCNS"
      },
      "outputs": [],
      "source": [
        "###########################\n",
        "##### Helper Function #####\n",
        "###########################\n",
        "def load_data(file_path):\n",
        "  ''' Load points and occupancy values from file.\n",
        "\n",
        "  Args:\n",
        "  file_path (string): path to file\n",
        "  '''\n",
        "  data_dict = np.load(file_path)\n",
        "  points = data_dict['points']\n",
        "  occupancies = data_dict['occupancies']\n",
        "\n",
        "  # Unpack data format of occupancies\n",
        "  occupancies = np.unpackbits(occupancies)[:points.shape[0]]\n",
        "  occupancies = occupancies.astype(np.float32)\n",
        "\n",
        "  # Align z-axis with top of object\n",
        "  points = np.stack([points[:, 0], -points[:, 2], points[:, 1]], 1)\n",
        "\n",
        "  return points, occupancies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-Hw2MmhrMdg"
      },
      "outputs": [],
      "source": [
        "###########################\n",
        "##### Helper Function #####\n",
        "###########################\n",
        "def visualize_occupancy(points, occupancies, n=50000):\n",
        "  ''' Visualize points and occupancy values.\n",
        "\n",
        "  Args:\n",
        "  points (torch.Tensor or np.ndarray): 3D coordinates of the points\n",
        "  occupancies (torch.Tensor or np.ndarray): occupancy values for the points\n",
        "  n (int): maximum number of points to visualize\n",
        "  '''\n",
        "  # if needed convert torch.tensor to np.ndarray\n",
        "  if isinstance(points, torch.Tensor):\n",
        "    points = points.detach().cpu().numpy()\n",
        "  if isinstance(occupancies, torch.Tensor):\n",
        "    occupancies = occupancies.detach().cpu().numpy()\n",
        "\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(projection='3d')\n",
        "\n",
        "  n = min(len(points), n)\n",
        "\n",
        "  # visualize a random subset of n points\n",
        "  idcs = np.random.randint(0, len(points), n)\n",
        "  points = points[idcs]\n",
        "  occupancies = occupancies[idcs]\n",
        "\n",
        "  # define colors\n",
        "  red = np.array([1,0,0,0.5]).reshape(1, 4).repeat(n,0)     # plot occupied points in red with alpha=0.5\n",
        "  blue = np.array([0,0,1,0.01]).reshape(1, 4).repeat(n,0)   # plot free points in blue with alpha=0.01\n",
        "  occ = occupancies.reshape(n, 1).repeat(4, 1)              # reshape to RGBA format to determine color\n",
        "\n",
        "  color = np.where(occ == 1, red, blue)                     # occ=1 -> red, occ=0 -> blue\n",
        "  \n",
        "  # plot the points\n",
        "  ax.scatter(*points.transpose(), color=color)\n",
        "\n",
        "  # make it pretty\n",
        "  ax.set_xlabel('X')\n",
        "  ax.set_ylabel('Y')\n",
        "  ax.set_zlabel('Z')\n",
        "  \n",
        "  ax.set_xlim(-0.5, 0.5)\n",
        "  ax.set_ylim(-0.5, 0.5)\n",
        "  ax.set_zlim(-0.5, 0.5)\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcr42Y6Noge0"
      },
      "source": [
        "Let's take a look at the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "FXETH9VEts2d",
        "outputId": "391bbbe5-5526-4b2f-836e-e68253169be1"
      },
      "outputs": [],
      "source": [
        "points, occupancies = load_data('data/points.npz')\n",
        "visualize_occupancy(points, occupancies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaIHpAT4u9eU"
      },
      "source": [
        "## Representing the Object Implicitly\n",
        "\n",
        "Instead of using a set of explicit 3D points with occupancy values, our goal is now to encode the 3D shape *implicitly* by the decision boundary of a classifier. The classifier is parametrized as a simple fully connected neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ax-NAaFfwhzb"
      },
      "source": [
        "This brings us to our first exercise function. We first need to split the data into a training and a validation set.\n",
        "Split the data randomly and use 80% for the training and 20% for the validation set.\n",
        "\n",
        "*Hint 1*: `ɯopuɐɹ˙du` uᴉ suoᴉʇɔunɟ lnɟǝsn ǝɯos puᴉɟ ʇɥƃᴉɯ no⅄"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjOtJHwiZ1AE"
      },
      "outputs": [],
      "source": [
        "###########################\n",
        "#### Exercise Function ####\n",
        "###########################\n",
        "def get_train_val_split(points, occupancies):\n",
        "  ''' Split data into train and validation set.\n",
        "  \n",
        "  Args:\n",
        "  points (torch.Tensor or np.ndarray): 3D coordinates of the points\n",
        "  occupancies (torch.Tensor or np.ndarray): occupancy values for the points\n",
        "  '''\n",
        "  \n",
        "  # Insert your code here\n",
        "\n",
        "  # this converts the points and labels from numpy.ndarray to a pytorch dataset\n",
        "  train_set = torch.utils.data.TensorDataset(torch.from_numpy(train_points), torch.from_numpy(train_occs))\n",
        "  val_set = torch.utils.data.TensorDataset(torch.from_numpy(val_points), torch.from_numpy(val_occs))\n",
        "  return train_set, val_set\n",
        "\n",
        "train_set, val_set = get_train_val_split(points, occupancies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YHt0wgX0954"
      },
      "source": [
        "We will train our network with batches of data, so let's define data loaders for training and validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ir9NduT509eK"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set, batch_size=batch_size, num_workers=1, shuffle=True, drop_last=True       # randomly shuffle the training data and potentially drop last batch\n",
        ")\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_set, batch_size=batch_size, num_workers=1, shuffle=False, drop_last=False        # do not shuffle validation set and do not potentially drop last batch\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xHgW6XA79lG"
      },
      "source": [
        "Let's do a quick sanity check to validate if our splits are correct:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "_lpSf0CT8EqS",
        "outputId": "d8f6b4c5-2c35-4b1e-85b1-5a814fb71ab2"
      },
      "outputs": [],
      "source": [
        "for loader in [train_loader, val_loader]:\n",
        "  check_points, check_occs = [], []\n",
        "  \n",
        "  for pts, occs in train_loader:\n",
        "    check_points.extend(pts)\n",
        "    check_occs.extend(occs)\n",
        "    if len(check_points) >= 10000:      # only visualize some points\n",
        "      break\n",
        "  \n",
        "  check_points, check_occs = torch.stack(check_points), torch.stack(check_occs)\n",
        "  visualize_occupancy(check_points, check_occs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yE_Tkz4k18rE"
      },
      "source": [
        "Does this look correct? If it does, it is time to define our classifier. We will implement this as a PyTorch module that we call *OccNet*. Complete the following class such that we obtain a network with **4 hidden layers of hidden dimension 64** (6 layers in total, 4 hidden + 1 input + 1 output). \n",
        "The model takes a batch of 3D points as input and should predict a single occupancy value for each point.\n",
        "Use the PyTorch class `nn.Linear` for the linear layers and `nn.ReLU` as activation function.\n",
        "\n",
        "*Hint 2*: ˙*ɹǝʎɐl ʇndʇno ǝɥʇ ɹoɟ ʇdǝɔxǝ* ɹǝʎɐl ɹɐǝuᴉl ʎɹǝʌǝ ɹǝʇɟɐ pǝpǝǝu sᴉ uoᴉʇɔunɟ uoᴉʇɐʌᴉʇɔɐ ǝɥ┴"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "U7VrlssHUIO-",
        "outputId": "4d10451d-9eec-4168-d3a6-6ff7346acae1"
      },
      "outputs": [],
      "source": [
        "###########################\n",
        "#### Exercise Function ####\n",
        "###########################\n",
        "class OccNet(nn.Module):\n",
        "  \"\"\" Network to predict an occupancy value for every 3D location. \n",
        "  \n",
        "  Args:\n",
        "  size_h (int): hidden dimension\n",
        "  n_hidden (int): number of hidden layers\n",
        "  \"\"\"\n",
        "  def __init__(self, size_h=64, n_hidden=4):\n",
        "    super().__init__()\n",
        "    \n",
        "    # Insert your code here\n",
        "\n",
        "    self.main = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, pts):\n",
        "    return self.main(pts).squeeze(-1)       # squeeze dimension of the single output value\n",
        "\n",
        "model = OccNet(size_h=64, n_hidden=4)\n",
        "\n",
        "# put the model on the GPU to accelerate training\n",
        "if torch.cuda.is_available():\n",
        "  model = model.cuda()\n",
        "else:\n",
        "  print('Fall back to CPU - GPU usage is recommended, e.g. using Google Colab.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrbgeDF64WT7"
      },
      "source": [
        "We train the classifier with binary cross entropy as objective and the Adam optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIaNN--tb0U0"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCEWithLogitsLoss(reduction='none')    # binary cross entropy loss + softmax\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLNtFuL047eT"
      },
      "source": [
        "Now everything is set! Let us write the training loop for our model.\n",
        "\n",
        "*Hint 3*: ˙[lɐᴉɹoʇnʇ ɥɔɹo┴ʎԀ](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) sᴉɥʇ ɟo ɹnoɟ ʇuᴉod ʇɐ ʞool ɐ ǝʞɐʇ ǝldɯɐxǝ uɐ ɹoℲ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "GPLyeS9KXFcs",
        "outputId": "3eaa7b9a-669d-490a-a213-38d68987c6ce"
      },
      "outputs": [],
      "source": [
        "###########################\n",
        "#### Exercise Function ####\n",
        "###########################\n",
        "def train_model(model, train_loader, val_loader, optimizer, criterion, nepochs=15, eval_every=100, out_dir='output'):\n",
        "  \n",
        "  liveloss = PlotLosses()   # to plot training progress\n",
        "  losses = {'loss': None,\n",
        "            'val_loss': None}\n",
        "\n",
        "  best = float('inf')\n",
        "  it = 0\n",
        "  for epoch in range(nepochs):\n",
        "\n",
        "    losses['loss'] = []       # initialize emtpy container for training losses\n",
        "    for pts, occ in train_loader:\n",
        "      it += 1\n",
        "\n",
        "      # Insert your code here\n",
        "\n",
        "      losses['loss'].append(loss.item())\n",
        "\n",
        "      if (it == 1) or (it % eval_every == 0):\n",
        "        \n",
        "        with torch.no_grad():\n",
        "          val_loss = []\n",
        "          for val_pts, val_occ in val_loader:\n",
        "            \n",
        "            # Insert your code here\n",
        "          \n",
        "            val_loss.extend(val_loss_i)\n",
        "          val_loss = torch.stack(val_loss).mean().item()\n",
        "          \n",
        "          if val_loss < best:     # keep track of best model\n",
        "            best = val_loss\n",
        "            torch.save(model.state_dict(), os.path.join(out_dir, 'model_best.pt'))\n",
        "\n",
        "    # update liveplot with latest values\n",
        "    losses['val_loss'] = val_loss\n",
        "    losses['loss'] = np.mean(losses['loss'])     # average over all training losses\n",
        "    liveloss.update(losses)\n",
        "    liveloss.send()\n",
        "\n",
        "train_model(model, train_loader, val_loader, optimizer, criterion, nepochs=25, eval_every=100, out_dir=out_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIQPhX-Dfuzf"
      },
      "source": [
        "Do training and validation loss curves look good? Or do you see any under / overfitting?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc3UkBu0IjcJ"
      },
      "source": [
        "Great! We have now a trained occupancy network that encodes our 3D shape."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xca6x9-DLQ2j"
      },
      "source": [
        "## Extracting the Object from the Implicit Representation\n",
        "\n",
        "Let us now try to get back the 3D shape using only the trained network. To this end, we define the following helper function to obtain a grid of equidistant 3D sampling points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkfMK6XjSqj2"
      },
      "outputs": [],
      "source": [
        "###########################\n",
        "#### Helper Function ######\n",
        "###########################\n",
        "def make_grid(xmin, xmax, resolution):\n",
        "  \"\"\" Create equidistant points on 3D grid (cube shaped).\n",
        "  \n",
        "  Args:\n",
        "  xmin (float): minimum for x,y,z\n",
        "  xmax (float): number of hidden layers\n",
        "  \"\"\"\n",
        "  grid_1d = torch.linspace(xmin, xmax, resolution)\n",
        "  grid_3d = torch.stack(torch.meshgrid(grid_1d, grid_1d, grid_1d), -1)\n",
        "  return grid_3d.flatten(0, 2)     # return as flattened tensor: RxRxRx3 -> (R^3)x3\n",
        "\n",
        "resolution = 128          # use 128 grid points in each of the three dimensions -> 128^3 query points\n",
        "grid = make_grid(-0.5, 0.5, resolution)\n",
        "\n",
        "# wrap query points in data loader\n",
        "batch_size = 128\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    grid, batch_size=128, num_workers=1, shuffle=False, drop_last=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3y6cNx1LZjL"
      },
      "source": [
        "Evaluate the best model on all of the grid points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snoCKaQlgc-S",
        "outputId": "9bef3d47-d8cb-4210-c747-56b8df89ea1e"
      },
      "outputs": [],
      "source": [
        "###########################\n",
        "#### Exercise Function ####\n",
        "###########################\n",
        "weights_best = torch.load(os.path.join(out_dir, 'model_best.pt'))     # we saved the best model there in the training loop\n",
        "model.load_state_dict(weights_best)\n",
        "\n",
        "# Insert your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "MFwZKlSMOmqj",
        "outputId": "51fe654d-6677-4021-8a5f-fa78016c0c0b"
      },
      "outputs": [],
      "source": [
        "grid_occupancies = grid_values > 0.       # convert model scores to classification score\n",
        "visualize_occupancy(grid, grid_occupancies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VeQTw5wNqv2"
      },
      "source": [
        "Does it look as expected? If it does, let's finish off this exercise by extract the mesh using the *Marching Cubes* algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "tOWM03jRN8mw",
        "outputId": "a9e16a90-8e83-4fa0-c9f0-53d5432c919c"
      },
      "outputs": [],
      "source": [
        "# extract mesh with Marching Cubes\n",
        "threshold = 0. # because grid values are model scores\n",
        "assert (grid_values.min() <= threshold) and (grid_values.max() >= threshold), \"Threshold is not in range of predicted values\"\n",
        "\n",
        "vertices, faces, _, _ = marching_cubes(grid_values.reshape(resolution, resolution, resolution).numpy(), \n",
        "                                                  threshold, \n",
        "                                                  spacing=(1/(resolution-1), 1/(resolution-1), 1/(resolution-1)),\n",
        "                                                  allow_degenerate=False)\n",
        "\n",
        "# plot mesh\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.plot_trisurf(vertices[:, 0], vertices[:,1], triangles=faces, Z=vertices[:,2])\n",
        "\n",
        "ax.set_xlim(0, 1)\n",
        "ax.set_ylim(0, 1)\n",
        "ax.set_zlim(0, 1)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsjDHoN0QDhX"
      },
      "source": [
        "Great job! You now gained hands-on experience with representations of 3D shapes! \n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "implicit.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
